# Symancy Pre-MVP Overview

**Дата:** 2025-09-16  
**Цель документа:** зафиксировать текущее состояние предварительной автоматизации, которая использовалась для проверки гипотез по анализу кофейной гущи, и обозначить ограничения перед миграцией в промышленную архитектуру.

## 1. Общее описание
- Канал взаимодействия: Telegram-бот обрабатывает входящие сообщения пользователей.
- Поддерживаемые типы запросов: изображения чашки с кофейной гущей и текстовые вопросы/уточнения.
- Логика обработки реализована в виде последовательного workflow, который оркестрирует вызовы внешних сервисов без полноценного бэкенда.
- Основные зависимости: Telegram Bot API, OpenRouter (vision и текстовые модели), PostgreSQL (контекстные сессии), временное файловое хранилище внутри workflow.

## 2. Пользовательский сценарий
1. Пользователь отправляет в чат фотографию или текстовый вопрос.
2. Сценарий различает сообщения с изображением и текстовые запросы.
3. Для изображений запускается цепочка: скачивание оригинала → нормализация размера → визуальный анализ AI-моделью → текстовая интерпретация «Ариной».
4. Для текстовых запросов запускается диалоговый ответ «Арины» с учетом истории.
5. Ответ форматируется под требования Telegram и отправляется частями с имитацией набора текста.

## 3. Реализованные компоненты

### 3.1. Приём и подготовка данных
- Webhook получает все события (`updates = '*'`) и сохраняет бинарные данные изображений.
- Для фотографий выбирается максимальное доступное разрешение (`message.photo[-1]`), сохраняются `chat_id`, `message_id`, `file_id`.
- Изображения приводятся к 800×800 px, качество регулируется (JPEG, 80%), обеспечивая предсказуемый размер файла для дальнейшего анализа.

### 3.2. Визуальный анализ
- Используется модель `deepcogito/cogito-v2-preview-llama-109b-moe` через провайдера OpenRouter.
- В модель передается base64-кодированное изображение и расширенный системный промпт, который описывает технику поиска паттернов (животные, фигуры, символы, абстрактные элементы) и структуру ответа.
- Результат — структурированный текст с описанием ключевых паттернов, пригодный для последующей психологической интерпретации.

### 3.3. Психологическая интерпретация («Арина»)
- Созданы два агентных промпта:
  - **Arina writer** — формирует основное толкование на основе визуального описания.
  - **Arina answerer** — отвечает на уточняющие или текстовые запросы пользователей.
- Для генерации используются две подключенные языковые модели (Qwen 235B и GPT OSS 120B) с fallback-повторными попытками.
- Контекст прошлых сообщений загружается из PostgreSQL (хранится до 20 итераций на пользователя), что обеспечивает непрерывность диалога.
- Строго задан формат вывода: ответы готовятся в HTML (поддерживаемые теги Telegram), сбалансированы по тону (сочетание поддержки и честной обратной связи), содержат практические рекомендации.

### 3.4. Форматирование и отправка
- Markdown-конвертер и дополнительные скрипты очищают ответы от неподдерживаемых Telegram-тегов, преобразуют списки и заголовки, следят за безопасными символами.
- Дополнительный скрипт разбивает длинные ответы на части с балансировкой HTML-тегов, чтобы укладываться в лимит 4096 символов и избегать ошибок парсинга.
- Перед каждой частью ответа отправляется `chat_action=typing`, а между частями делается пауза (4 секунды), что обеспечивает более естественный UX.
- Ответы отправляются через Telegram Bot API в HTML-режиме (`parse_mode=HTML`).

## 4. Интеграции и данные
- **Telegram Bot API:** webhooks, загрузка файлов, отправка сообщений и chat actions.
- **OpenRouter:** vision-модель для первичного анализа изображения + две языковые модели для текстовой работы.
- **PostgreSQL:** хранение контекста диалога (session key = `message.from.id`, окно 20 сообщений), используется для персонализации ответов.
- **Локальное временное хранилище workflow:** хранение промежуточных файлов для передачи в AI.

## 5. Ограничения и пробелы
- Отсутствует полноценный бэкенд: нет единой базы пользователей, подписок, транзакций и истории анализов.
- Нет тарификации и платежной логики, лимиты не учитываются.
- Отсутствует хранение изображений и результатов в постоянном хранилище — текущие данные не сохраняются для аналитики.
- Нет мониторинга, алертов и журналирования: при сбоях требуется ручная диагностика.
- Обработка ошибок ограничена — в ряде случаев workflow продолжает работу с неполными данными.
- Секреты (API-токены) вшиты напрямую в вызовы, необходим переход к безопасному хранилищу.
- Нет инструментов модерации, фильтрации NSFW и защиты от флуд-атак.
- Не проработана многоязычная поддержка и корректная локализация.

## 6. Выводы перед миграцией в MVP
- Текущий сценарий подтверждает жизнеспособность базовой ценности: обработка фото → выделение паттернов → психологическая интерпретация.
- Требуется переработка в сервисную архитектуру: вынести обработку в микросервисы/воркеры, внедрить постоянное хранилище и очередь задач.
- Необходимо формализовать промпты и сценарии как версионируемые артефакты, интегрировать их в репозиторий.
- Требуется добавить контроль качества, мониторинг, аудит действий и механизмы отката.
- Программный стек MVP должен сохранить сильные стороны текущей автоматизации (качество интерпретаций, UX ответов) и закрыть выявленные пробелы по надежности, платежам и аналитике.

